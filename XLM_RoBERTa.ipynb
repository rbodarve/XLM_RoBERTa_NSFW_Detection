{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31c747da8d934f38adf6fd4177d82e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e888fe0f59454fd8be1adcc970bf8c6f",
              "IPY_MODEL_386669778383468dabff518daab31c9b",
              "IPY_MODEL_586e26dad1d549909594b25abaf7b92b"
            ],
            "layout": "IPY_MODEL_2c52d55a68e24742adf23231607c8da4"
          }
        },
        "e888fe0f59454fd8be1adcc970bf8c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bd2745b066e4d6894d913d6e615a298",
            "placeholder": "​",
            "style": "IPY_MODEL_28a7b4d751f6408da8ce504190950a09",
            "value": "Map: 100%"
          }
        },
        "386669778383468dabff518daab31c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15f353c742f0403aae3b546014cbebf8",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6014f7ebbf84451089d2a2c198215ebc",
            "value": 60
          }
        },
        "586e26dad1d549909594b25abaf7b92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdb6e895839f4df89ca2ee1969c2e147",
            "placeholder": "​",
            "style": "IPY_MODEL_3ac494f6437746f486749ff29e362659",
            "value": " 60/60 [00:00&lt;00:00, 1962.72 examples/s]"
          }
        },
        "2c52d55a68e24742adf23231607c8da4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bd2745b066e4d6894d913d6e615a298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28a7b4d751f6408da8ce504190950a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15f353c742f0403aae3b546014cbebf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6014f7ebbf84451089d2a2c198215ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdb6e895839f4df89ca2ee1969c2e147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ac494f6437746f486749ff29e362659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feb686e58f5a4fb0a9b05695d919d101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68b439b653da46abb9fdf35a7129ea99",
              "IPY_MODEL_90794681664441df8a68cc312a90213f",
              "IPY_MODEL_cf82b58f2a824eadba97b0d99289e2be"
            ],
            "layout": "IPY_MODEL_f2ff61ac46c24213a6a6383b813f2781"
          }
        },
        "68b439b653da46abb9fdf35a7129ea99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cccc9ac7c41422191bf55478b2560c1",
            "placeholder": "​",
            "style": "IPY_MODEL_1646530e020d4d7cb5e617e66ff44bc6",
            "value": "Map: 100%"
          }
        },
        "90794681664441df8a68cc312a90213f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e17d4beebfb741f7a72bbd28695a7bd5",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee5645bb694c4a10916aef46a5c8341e",
            "value": 15
          }
        },
        "cf82b58f2a824eadba97b0d99289e2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fc786a8117646d7992d3ff9b95e3387",
            "placeholder": "​",
            "style": "IPY_MODEL_6de0e7134b21407eaea84d55aea34c55",
            "value": " 15/15 [00:00&lt;00:00, 495.86 examples/s]"
          }
        },
        "f2ff61ac46c24213a6a6383b813f2781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cccc9ac7c41422191bf55478b2560c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1646530e020d4d7cb5e617e66ff44bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e17d4beebfb741f7a72bbd28695a7bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee5645bb694c4a10916aef46a5c8341e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fc786a8117646d7992d3ff9b95e3387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de0e7134b21407eaea84d55aea34c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ywa5gS3H-KIx"
      },
      "outputs": [],
      "source": [
        "#import shutil\n",
        "#shutil.rmtree('/content/metrics', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XLM-RoBERTa"
      ],
      "metadata": {
        "id": "resoeJaD-mKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_recall_fscore_support\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        "    XLMRobertaTokenizer,\n",
        "    XLMRobertaForSequenceClassification\n",
        ")\n",
        "from datasets import Dataset\n",
        "import tempfile\n",
        "import subprocess\n",
        "import sys"
      ],
      "metadata": {
        "id": "40U2x5_g-t9u"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT LIBRARIES AND SETUP"
      ],
      "metadata": {
        "id": "rr3TPcBg-wNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_recall_fscore_support\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import Dataset\n",
        "import tempfile\n",
        "import subprocess\n",
        "import sys"
      ],
      "metadata": {
        "id": "_02P0W8w-zZa"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Checking and installing dependencies...\")\n",
        "install_requirements()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH7ujfkr-1QN",
        "outputId": "6f2f94b5-9841-4c45-bc81-21d2b0f32a55"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking and installing dependencies...\n",
            "Installing scikit-learn...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from optimum.onnxruntime import ORTModelForSequenceClassification\n",
        "    from optimum.onnxruntime.configuration import OptimizationConfig\n",
        "    ONNX_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Optimum ONNX Runtime not available, ONNX export will be limited\")\n",
        "    ONNX_AVAILABLE = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vl4PzZ8HPMo",
        "outputId": "eed0b36f-9a6e-4852-ef51-b0ced2abd267"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimum ONNX Runtime not available, ONNX export will be limited\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All dependencies loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pihPjHWb-4a_",
        "outputId": "33f09507-4200-48fa-95d7-992120ee9075"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dependencies loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD AND PREPARE DATASET"
      ],
      "metadata": {
        "id": "n7LbJgAk-7dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(csv_path='dataset.csv'):\n",
        "    print(f\"Loading multilingual dataset from {csv_path}...\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
        "\n",
        "        # Validate required columns\n",
        "        required_cols = ['text', 'label']\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Clean and validate data\n",
        "        df = df.dropna(subset=['text', 'label'])\n",
        "        df['text'] = df['text'].astype(str)\n",
        "        df['label'] = df['label'].astype(int)\n",
        "\n",
        "        # Validate and normalize labels\n",
        "        unique_labels = sorted(df['label'].unique())\n",
        "        num_labels = len(unique_labels)\n",
        "\n",
        "        # Ensure labels are sequential starting from 0\n",
        "        if unique_labels != list(range(num_labels)):\n",
        "            print(\"Warning: Labels are not sequential starting from 0. Remapping...\")\n",
        "            label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
        "            df['label'] = df['label'].map(label_mapping)\n",
        "            print(f\"Label mapping: {label_mapping}\")\n",
        "\n",
        "        print(f\"Dataset validation complete. Clean shape: {df.shape}\")\n",
        "        print(f\"Number of classes: {num_labels}\")\n",
        "        print(f\"Label distribution:\\n{df['label'].value_counts().sort_index()}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Dataset file '{csv_path}' not found!\")\n",
        "        print(\"Creating a sample multilingual dataset for demonstration...\")\n",
        "        return create_sample_dataset()"
      ],
      "metadata": {
        "id": "bzVyf_N1--cL"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_sample_dataset():\n",
        "    sample_data = {\n",
        "        'text': [\n",
        "            # English samples (labels 0-2)\n",
        "            'This product is absolutely amazing and works perfectly!',\n",
        "            'Great quality and excellent customer service.',\n",
        "            'I highly recommend this to everyone, outstanding performance.',\n",
        "            'Love the design and functionality, very satisfied.',\n",
        "            'Exceptional value for money, exceeded expectations.',\n",
        "\n",
        "            'The product is okay, meets basic requirements.',\n",
        "            'Average quality, nothing special but works fine.',\n",
        "            'Standard features, typical for this price range.',\n",
        "            'It works as described, no major complaints.',\n",
        "            'Decent product, could be better but acceptable.',\n",
        "\n",
        "            'Terrible quality, completely disappointed with purchase.',\n",
        "            'Worst customer service experience ever encountered.',\n",
        "            'Product broke after just one day of use.',\n",
        "            'Would not recommend, waste of money and time.',\n",
        "            'Poor build quality and unreliable performance.',\n",
        "\n",
        "            # Spanish samples\n",
        "            'Este producto es absolutamente increíble, funciona perfectamente.',\n",
        "            'Excelente calidad y servicio al cliente excepcional.',\n",
        "            'Lo recomiendo mucho, rendimiento extraordinario y confiable.',\n",
        "            'Me encanta el diseño, muy satisfecho con la compra.',\n",
        "            'Valor excepcional, superó todas mis expectativas completamente.',\n",
        "\n",
        "            'El producto está bien, cumple con lo básico necesario.',\n",
        "            'Calidad promedio, nada especial pero funciona correctamente.',\n",
        "            'Características estándar, típico para este rango de precios.',\n",
        "            'Funciona como se describe, sin quejas importantes.',\n",
        "            'Producto decente, podría ser mejor pero aceptable.',\n",
        "\n",
        "            'Calidad terrible, completamente decepcionado con la compra realizada.',\n",
        "            'La peor experiencia de servicio al cliente jamás experimentada.',\n",
        "            'El producto se rompió después de solo un día.',\n",
        "            'No lo recomendaría, pérdida de dinero y tiempo.',\n",
        "            'Mala calidad de construcción y rendimiento poco confiable.',\n",
        "\n",
        "            # Tagalog samples\n",
        "            'Napakaganda ng produktong ito, perpektong gumagana!',\n",
        "            'Napakahusay ng kalidad at serbisyo sa customer.',\n",
        "            'Highly recommended ko ito sa lahat, outstanding performance.',\n",
        "            'Love ko ang design, very satisfied sa purchase.',\n",
        "            'Exceptional value for money, sobra sa expectations.',\n",
        "\n",
        "            'Okay lang ang produkto, nakakameet ng basic requirements.',\n",
        "            'Average quality, walang special pero gumagana naman.',\n",
        "            'Standard features, typical sa price range na ito.',\n",
        "            'Gumagana naman as described, walang major complaints.',\n",
        "            'Decent product, pwede pa mas better pero acceptable.',\n",
        "\n",
        "            'Napakasama ng quality, disappointed ako sa purchase.',\n",
        "            'Worst customer service experience na naranasan ko.',\n",
        "            'Nasira ang produkto after one day lang.',\n",
        "            'Hindi ko irerekumenda, sayang ang pera at oras.',\n",
        "            'Pangit ng build quality at hindi reliable performance.',\n",
        "\n",
        "            # French samples\n",
        "            'Ce produit est absolument incroyable, fonctionne parfaitement bien!',\n",
        "            'Excellente qualité et service client exceptionnel et professionnel.',\n",
        "            'Je le recommande vivement, performances extraordinaires et fiables.',\n",
        "            'J\\'adore le design, très satisfait de cet achat.',\n",
        "            'Valeur exceptionnelle, a dépassé toutes mes attentes complètement.',\n",
        "\n",
        "            'Le produit est correct, répond aux exigences de base.',\n",
        "            'Qualité moyenne, rien de spécial mais fonctionne bien.',\n",
        "            'Fonctionnalités standard, typique pour cette gamme de prix.',\n",
        "            'Fonctionne comme décrit, pas de plaintes majeures importantes.',\n",
        "            'Produit décent, pourrait être mieux mais acceptable globalement.',\n",
        "\n",
        "            'Qualité terrible, complètement déçu de cet achat récent.',\n",
        "            'La pire expérience de service client jamais vécue.',\n",
        "            'Le produit s\\'est cassé après seulement une journée.',\n",
        "            'Je ne le recommanderais pas, perte d\\'argent.',\n",
        "            'Mauvaise qualité de construction et performances peu fiables.',\n",
        "\n",
        "            # German samples\n",
        "            'Dieses Produkt ist absolut fantastisch und funktioniert perfekt!',\n",
        "            'Ausgezeichnete Qualität und hervorragender Kundenservice immer.',\n",
        "            'Ich empfehle es sehr, außergewöhnliche Leistung und Zuverlässigkeit.',\n",
        "            'Ich liebe das Design, sehr zufrieden mit dem Kauf.',\n",
        "            'Außergewöhnlicher Wert, hat alle Erwartungen vollständig übertroffen.',\n",
        "\n",
        "            'Das Produkt ist okay, erfüllt die grundlegenden Anforderungen gut.',\n",
        "            'Durchschnittliche Qualität, nichts Besonderes aber funktioniert einwandfrei.',\n",
        "            'Standard-Features, typisch für diese Preisklasse und Kategorie.',\n",
        "            'Funktioniert wie beschrieben, keine größeren Beschwerden vorhanden.',\n",
        "            'Anständiges Produkt, könnte besser sein aber akzeptabel.',\n",
        "\n",
        "            'Schreckliche Qualität, völlig enttäuscht von diesem Kauf heute.',\n",
        "            'Die schlechteste Kundenservice-Erfahrung, die ich je gemacht habe.',\n",
        "            'Das Produkt ging nach nur einem Tag kaputt.',\n",
        "            'Würde ich nicht empfehlen, Geld- und Zeitverschwendung.',\n",
        "            'Schlechte Bauqualität und unzuverlässige Leistung durchgehend.',\n",
        "        ],\n",
        "        'label': (\n",
        "            # English: 5 positive, 5 neutral, 5 negative\n",
        "            [2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] +\n",
        "            # Spanish: 5 positive, 5 neutral, 5 negative\n",
        "            [2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] +\n",
        "            # Tagalog: 5 positive, 5 neutral, 5 negative\n",
        "            [2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] +\n",
        "            # French: 5 positive, 5 neutral, 5 negative\n",
        "            [2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] +\n",
        "            # German: 5 positive, 5 neutral, 5 negative\n",
        "            [2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
        "        )\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(sample_data)\n",
        "    df.to_csv('dataset.csv', index=False)\n",
        "    print(\"Sample multilingual sentiment dataset created and saved as 'dataset.csv'\")\n",
        "    print(\"Dataset includes English, Spanish, Tagalog, French, and German samples\")\n",
        "    print(\"Labels: 0=Negative, 1=Neutral, 2=Positive\")\n",
        "    print(f\"Total samples: {len(df)} across 5 languages\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "0a5WSdnJ_Con"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(df, test_size=0.2, random_state=42):\n",
        "    print(f\"Splitting dataset: {test_size*100}% for validation...\")\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        df['text'].tolist(),\n",
        "        df['label'].tolist(),\n",
        "        test_size=test_size,\n",
        "        random_state=random_state,\n",
        "        stratify=df['label']\n",
        "    )\n",
        "\n",
        "    print(f\"Training set: {len(X_train)} samples\")\n",
        "    print(f\"Validation set: {len(X_val)} samples\")\n",
        "\n",
        "    return X_train, X_val, y_train, y_val"
      ],
      "metadata": {
        "id": "n8nadu-E_fXU"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOKENIZATION AND PREPROCESSING"
      ],
      "metadata": {
        "id": "t2dw7FWN_iHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tokenized_datasets(X_train, X_val, y_train, y_val, model_name):\n",
        "    \"\"\"Tokenize the datasets using the XLM-RoBERTa tokenizer\"\"\"\n",
        "    print(\"Loading XLM-RoBERTa tokenizer and creating tokenized datasets...\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # XLM-RoBERTa uses SentencePiece tokenizer, similar to RoBERTa\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    print(f\"Tokenizer vocabulary size: {tokenizer.vocab_size}\")\n",
        "    print(f\"Model max length: {tokenizer.model_max_length}\")\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = Dataset.from_dict({\n",
        "        'text': X_train,\n",
        "        'labels': y_train\n",
        "    })\n",
        "\n",
        "    val_dataset = Dataset.from_dict({\n",
        "        'text': X_val,\n",
        "        'labels': y_val\n",
        "    })\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples['text'],\n",
        "            truncation=True,\n",
        "            padding=False,  # Will be handled by data collator\n",
        "            max_length=256  # Good for multilingual text processing\n",
        "        )\n",
        "\n",
        "    # Tokenize datasets\n",
        "    print(\"Tokenizing training dataset...\")\n",
        "    train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    print(\"Tokenizing validation dataset...\")\n",
        "    val_tokenized = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    print(\"Tokenization complete!\")\n",
        "    print(f\"Sample tokenized text length: {len(train_tokenized[0]['input_ids'])}\")\n",
        "\n",
        "    return train_tokenized, val_tokenized, tokenizer"
      ],
      "metadata": {
        "id": "YB_9DFNf_mr5"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TRAINING"
      ],
      "metadata": {
        "id": "uDBa6Wqd_pVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_dataset, val_dataset, tokenizer, model_name, output_dir, num_labels):\n",
        "    \"\"\"Train the XLM-RoBERTa model for multilingual classification\"\"\"\n",
        "    print(\"Initializing XLM-RoBERTa model for multilingual classification training...\")\n",
        "\n",
        "    # Load model with appropriate number of labels\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=num_labels,\n",
        "        problem_type=\"single_label_classification\"\n",
        "    )\n",
        "\n",
        "    print(f\"Model loaded with {model.num_parameters():,} parameters\")\n",
        "    print(f\"Model architecture: {model.config.hidden_size} hidden, {model.config.num_hidden_layers} layers\")\n",
        "\n",
        "    # Ensure model uses the correct pad_token_id\n",
        "    if tokenizer.pad_token_id is not None:\n",
        "        model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    # Data collator\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    # Training arguments optimized for XLM-RoBERTa\n",
        "    training_args_dict = {\n",
        "        'output_dir': output_dir,\n",
        "        'num_train_epochs': 3,  # Standard for fine-tuning large models\n",
        "        'per_device_train_batch_size': 8,  # Conservative for 270M parameter model\n",
        "        'per_device_eval_batch_size': 8,\n",
        "        'learning_rate': 2e-5,  # Lower learning rate for large pre-trained model\n",
        "        'weight_decay': 0.01,\n",
        "        'warmup_ratio': 0.06,  # 6% warmup recommended for RoBERTa\n",
        "        'logging_dir': f'{output_dir}/logs',\n",
        "        'logging_steps': 25,\n",
        "        'save_total_limit': 2,\n",
        "        'load_best_model_at_end': True,\n",
        "        'metric_for_best_model': \"eval_f1_weighted\",\n",
        "        'greater_is_better': True,\n",
        "        'report_to': [],\n",
        "        'seed': 42,\n",
        "        'dataloader_num_workers': 0,\n",
        "        'remove_unused_columns': True,\n",
        "        'fp16': True,  # Mixed precision for efficiency\n",
        "        'dataloader_pin_memory': False,\n",
        "        'gradient_checkpointing': True,  # Save memory for large model\n",
        "        'max_grad_norm': 1.0,  # Gradient clipping\n",
        "        'lr_scheduler_type': 'cosine',  # Cosine learning rate schedule\n",
        "    }\n",
        "\n",
        "    # Add version-specific parameters\n",
        "    if hasattr(TrainingArguments, 'eval_strategy'):\n",
        "        training_args_dict['eval_strategy'] = \"steps\"\n",
        "        training_args_dict['eval_steps'] = 100\n",
        "        training_args_dict['save_strategy'] = \"steps\"\n",
        "        training_args_dict['save_steps'] = 100\n",
        "    else:\n",
        "        training_args_dict['evaluation_strategy'] = \"steps\"\n",
        "        training_args_dict['eval_steps'] = 100\n",
        "        training_args_dict['save_strategy'] = \"steps\"\n",
        "        training_args_dict['save_steps'] = 100\n",
        "\n",
        "    training_args = TrainingArguments(**training_args_dict)\n",
        "\n",
        "    def compute_metrics(eval_pred):\n",
        "        predictions, labels = eval_pred\n",
        "\n",
        "        # Handle different prediction formats\n",
        "        if isinstance(predictions, tuple):\n",
        "            predictions = predictions[0]\n",
        "\n",
        "        # Convert to numpy array if it's a tensor\n",
        "        if hasattr(predictions, 'numpy'):\n",
        "            predictions = predictions.numpy()\n",
        "\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Calculate comprehensive metrics\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "        f1_macro = f1_score(labels, predictions, average='macro')\n",
        "        f1_weighted = f1_score(labels, predictions, average='weighted')\n",
        "        precision_macro = precision_recall_fscore_support(labels, predictions, average='macro')[0]\n",
        "        recall_macro = precision_recall_fscore_support(labels, predictions, average='macro')[1]\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "            'precision_macro': precision_macro,\n",
        "            'recall_macro': recall_macro,\n",
        "        }\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the best model\n",
        "    print(f\"Saving model to {output_dir}...\")\n",
        "    trainer.save_model()\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    return trainer, model"
      ],
      "metadata": {
        "id": "D2_0ZksZ_u0P"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL EVALUATION"
      ],
      "metadata": {
        "id": "IaRXZ7Dp_w9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(trainer, X_val, y_val, output_dir, num_labels):\n",
        "    print(\"Evaluating XLM-RoBERTa model performance...\")\n",
        "\n",
        "    # Get predictions\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    # Get detailed predictions for classification report\n",
        "    predictions = trainer.predict(trainer.eval_dataset)\n",
        "\n",
        "    # Extract predictions from the prediction object\n",
        "    if hasattr(predictions, 'predictions'):\n",
        "        preds = predictions.predictions\n",
        "    else:\n",
        "        preds = predictions[0]\n",
        "\n",
        "    # Convert to numpy array if it's a tensor\n",
        "    if hasattr(preds, 'numpy'):\n",
        "        preds = preds.numpy()\n",
        "\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Generate classification report\n",
        "    if num_labels == 2:\n",
        "        target_names = ['NSFW', 'Safe']\n",
        "    elif num_labels == 3:\n",
        "        # Map: 0=NSFW, 1=Safe, 2=Safe (combining neutral and positive as Safe)\n",
        "        target_names = ['NSFW', 'Safe', 'Safe']\n",
        "        # Remap predictions: combine classes 1 and 2 into 'Safe'\n",
        "        y_val_binary = [0 if label == 0 else 1 for label in y_val]\n",
        "        y_pred_binary = [0 if pred == 0 else 1 for pred in y_pred]\n",
        "\n",
        "        # Use binary classification for final report\n",
        "        report = classification_report(\n",
        "            y_val_binary,\n",
        "            y_pred_binary,\n",
        "            target_names=['NSFW', 'Safe'],\n",
        "            digits=4\n",
        "        )\n",
        "\n",
        "        # Calculate binary metrics\n",
        "        accuracy = accuracy_score(y_val_binary, y_pred_binary)\n",
        "        f1_macro = f1_score(y_val_binary, y_pred_binary, average='macro')\n",
        "        f1_weighted = f1_score(y_val_binary, y_pred_binary, average='weighted')\n",
        "        precision_macro = precision_recall_fscore_support(y_val_binary, y_pred_binary, average='macro')[0]\n",
        "        recall_macro = precision_recall_fscore_support(y_val_binary, y_pred_binary, average='macro')[1]\n",
        "    else:\n",
        "        target_names = [f'Class_{i}' for i in range(num_labels)]\n",
        "        report = classification_report(\n",
        "            y_val,\n",
        "            y_pred,\n",
        "            target_names=target_names,\n",
        "            digits=4\n",
        "        )\n",
        "\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        f1_macro = f1_score(y_val, y_pred, average='macro')\n",
        "        f1_weighted = f1_score(y_val, y_pred, average='weighted')\n",
        "        precision_macro = precision_recall_fscore_support(y_val, y_pred, average='macro')[0]\n",
        "        recall_macro = precision_recall_fscore_support(y_val, y_pred, average='macro')[1]\n",
        "\n",
        "    # Prepare metrics text\n",
        "    task_description = \"Multilingual Content Safety Classification (NSFW vs Safe)\" if num_labels <= 3 else f\"Multilingual Text Classification ({num_labels} classes)\"\n",
        "\n",
        "    metrics_text = f\"\"\"XLM-RoBERTa Content Safety Classification Model Evaluation Results\n",
        "{'='*75}\n",
        "\n",
        "Model: FacebookAI/xlm-roberta-base\n",
        "Task: {task_description}\n",
        "Architecture: 12 layers, 768 hidden units, 270M parameters\n",
        "Languages: Supports 100+ languages including major world languages\n",
        "\n",
        "Performance Metrics:\n",
        "{'-'*40}\n",
        "Accuracy: {accuracy:.4f}\n",
        "F1-Score (Macro): {f1_macro:.4f}\n",
        "F1-Score (Weighted): {f1_weighted:.4f}\n",
        "Precision (Macro): {precision_macro:.4f}\n",
        "Recall (Macro): {recall_macro:.4f}\n",
        "\n",
        "Classification Report:\n",
        "{report}\n",
        "\n",
        "Training Results:\n",
        "{'-'*40}\n",
        "\"\"\"\n",
        "\n",
        "    for key, value in eval_results.items():\n",
        "        if isinstance(value, (int, float)):\n",
        "            metrics_text += f\"{key}: {value:.4f}\\n\"\n",
        "\n",
        "    # Save metrics\n",
        "    os.makedirs('metrics', exist_ok=True)\n",
        "    metrics_path = 'metrics/xlm_roberta_metrics.txt'\n",
        "\n",
        "    with open(metrics_path, 'w') as f:\n",
        "        f.write(metrics_text)\n",
        "\n",
        "    print(f\"Metrics saved to {metrics_path}\")\n",
        "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
        "    print(f\"F1-Score (Weighted): {f1_weighted:.4f}\")\n",
        "\n",
        "    return accuracy, report"
      ],
      "metadata": {
        "id": "dgxUhFqe_0b3"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX EXPORT"
      ],
      "metadata": {
        "id": "5PtHDRCK_3WG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_onnx(model_dir, onnx_path):\n",
        "    print(\"Exporting XLM-RoBERTa model to ONNX format...\")\n",
        "\n",
        "    try:\n",
        "        # Load the trained model\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        # Fix: Load tokenizer from original model name instead of saved directory\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
        "\n",
        "        # Create dummy input with multilingual sample\n",
        "        dummy_input = tokenizer(\n",
        "            \"This is a multilingual text sample for ONNX export testing\",\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=256,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        # Export to ONNX with optimization for XLM-RoBERTa\n",
        "        os.makedirs(os.path.dirname(onnx_path), exist_ok=True)\n",
        "        torch.onnx.export(\n",
        "            model,\n",
        "            tuple(dummy_input.values()),\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=14,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input_ids', 'attention_mask'],\n",
        "            output_names=['logits'],\n",
        "            dynamic_axes={\n",
        "                'input_ids': {0: 'batch_size', 1: 'sequence'},\n",
        "                'attention_mask': {0: 'batch_size', 1: 'sequence'},\n",
        "                'logits': {0: 'batch_size'}\n",
        "            }\n",
        "        )\n",
        "\n",
        "        print(f\"ONNX model exported to: {onnx_path}\")\n",
        "\n",
        "        # Get model size\n",
        "        model_size = os.path.getsize(onnx_path) / (1024 * 1024)\n",
        "        print(f\"ONNX model size: {model_size:.2f} MB\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ONNX export failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False"
      ],
      "metadata": {
        "id": "Nh7UnAAD_7p0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TENSORFLOW LITE EXPORT"
      ],
      "metadata": {
        "id": "XGdZ7Vl7_-tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_tflite_from_pt(model_dir, tflite_path):\n",
        "    try:\n",
        "        import tensorflow as tf\n",
        "        from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "        print(\"Converting XLM-RoBERTa PyTorch model to TensorFlow...\")\n",
        "\n",
        "        # Load and convert to TensorFlow\n",
        "        tf_model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "            model_dir,\n",
        "            from_pt=True\n",
        "        )\n",
        "\n",
        "        # Save as TensorFlow SavedModel\n",
        "        tf_saved_model_dir = os.path.join(model_dir, \"tf_saved_model\")\n",
        "        tf.saved_model.save(tf_model, tf_saved_model_dir)\n",
        "        print(f\"Saved intermediate TensorFlow model to {tf_saved_model_dir}\")\n",
        "\n",
        "        # Convert to TFLite with optimizations\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_saved_model_dir)\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "        # Additional optimizations for mobile deployment\n",
        "        converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        # Save TFLite model\n",
        "        os.makedirs(os.path.dirname(tflite_path), exist_ok=True)\n",
        "        with open(tflite_path, \"wb\") as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "        # Get model size\n",
        "        model_size = os.path.getsize(tflite_path) / (1024 * 1024)\n",
        "        print(f\"TFLite model successfully exported to: {tflite_path}\")\n",
        "        print(f\"TFLite model size: {model_size:.2f} MB\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"TensorFlow Lite export failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False"
      ],
      "metadata": {
        "id": "a5Exlx7tABgV"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "S-2To_L0ACRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"Starting XLM-RoBERTa Multilingual Text Classification Pipeline\")\n",
        "    print(\"=\"*75)\n",
        "\n",
        "    # Configuration - Updated to use XLM-RoBERTa model\n",
        "    MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
        "    OUTPUT_DIR = \"models/xlm_roberta_classification\"\n",
        "    ONNX_PATH = \"models/xlm_roberta_classification_model.onnx\"\n",
        "    TFLITE_PATH = \"models/xlm_roberta_classification_model.tflite\"\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    os.makedirs(\"metrics\", exist_ok=True)\n",
        "\n",
        "    print(f\"Using model: {MODEL_NAME}\")\n",
        "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
        "\n",
        "    # Step 1: Load dataset\n",
        "    df = load_dataset()\n",
        "    num_labels = len(df['label'].unique())\n",
        "\n",
        "    # Step 2: Split dataset\n",
        "    X_train, X_val, y_train, y_val = split_dataset(df)\n",
        "\n",
        "    # Step 3: Create tokenized datasets\n",
        "    train_dataset, val_dataset, tokenizer = create_tokenized_datasets(\n",
        "        X_train, X_val, y_train, y_val, MODEL_NAME\n",
        "    )\n",
        "\n",
        "    # Step 4: Train model\n",
        "    trainer, model = train_model(\n",
        "        train_dataset, val_dataset, tokenizer, MODEL_NAME, OUTPUT_DIR, num_labels\n",
        "    )\n",
        "\n",
        "    # Step 5: Evaluate model\n",
        "    accuracy, report = evaluate_model(trainer, X_val, y_val, OUTPUT_DIR, num_labels)\n",
        "\n",
        "    # Step 6: Export to ONNX\n",
        "    onnx_success = export_to_onnx(OUTPUT_DIR, ONNX_PATH)\n",
        "\n",
        "    # Step 7: Export to TFLite\n",
        "    tflite_success = export_to_tflite_from_pt(OUTPUT_DIR, TFLITE_PATH)\n",
        "\n",
        "    # Final output\n",
        "    print(\"\\n\" + \"=\"*75)\n",
        "    print(\"XLM-RoBERTa Multilingual Classification Training Complete!\")\n",
        "\n",
        "    if onnx_success:\n",
        "        print(f\"✅ ONNX model: {ONNX_PATH}\")\n",
        "    else:\n",
        "        print(\"❌ ONNX export: FAILED\")\n",
        "\n",
        "    if tflite_success:\n",
        "        print(f\"✅ TFLite model: {TFLITE_PATH}\")\n",
        "    else:\n",
        "        print(\"❌ TFLite export: FAILED\")\n",
        "\n",
        "    print(f\"\\nModel checkpoints: {OUTPUT_DIR}\")\n",
        "    print(f\"Metrics: metrics/xlm_roberta_metrics.txt\")\n",
        "    print(f\"Final validation accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "jf5Dv-hnAIG1"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INFERENCE"
      ],
      "metadata": {
        "id": "nWbaEcFsAIvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_inference(model_dir, test_texts=None):\n",
        "    if test_texts is None:\n",
        "        test_texts = [\n",
        "            # English samples\n",
        "            \"I absolutely love this amazing product, it's fantastic!\",\n",
        "            \"The product is okay, nothing particularly special about it.\",\n",
        "            \"Terrible quality, I'm completely disappointed with this purchase.\",\n",
        "\n",
        "            # Spanish samples\n",
        "            \"Este producto es absolutamente increÃ­ble, me encanta mucho.\",\n",
        "            \"El producto estÃ¡ bien, nada especialmente notable o destacable.\",\n",
        "            \"Calidad horrible, estoy completamente decepcionado con la compra.\",\n",
        "\n",
        "            # Tagalog samples\n",
        "            \"Napakaganda ng produktong ito, sobrang satisfied ako dito!\",\n",
        "            \"Okay lang naman ang produkto, walang special na features.\",\n",
        "            \"Sobrang pangit ng quality, disappointed ako sa purchase na ito.\",\n",
        "\n",
        "            # French samples\n",
        "            \"J'adore absolument ce produit, il est vraiment fantastique!\",\n",
        "            \"Le produit est correct, rien de particuliÃ¨rement remarquable vraiment.\",\n",
        "            \"QualitÃ© horrible, je suis complÃ¨tement dÃ©Ã§u de cet achat rÃ©cent.\",\n",
        "\n",
        "            # German samples\n",
        "            \"Ich liebe dieses Produkt absolut, es ist wirklich fantastisch!\",\n",
        "            \"Das Produkt ist okay, nichts besonders Bemerkenswertes daran wirklich.\",\n",
        "            \"Schreckliche QualitÃ¤t, ich bin vÃ¶llig enttÃ¤uscht von diesem Kauf.\",\n",
        "\n",
        "            # Italian samples\n",
        "            \"Amo assolutamente questo prodotto, Ã¨ davvero fantastico e perfetto!\",\n",
        "            \"Il prodotto va bene, niente di particolarmente notevole o speciale.\",\n",
        "            \"QualitÃ  orribile, sono completamente deluso da questo acquisto recente.\",\n",
        "\n",
        "            # Portuguese samples\n",
        "            \"Eu amo absolutamente este produto, Ã© realmente fantÃ¡stico e perfeito!\",\n",
        "            \"O produto estÃ¡ bem, nada particularmente notÃ¡vel ou especial mesmo.\",\n",
        "            \"Qualidade horrÃ­vel, estou completamente decepcionado com esta compra.\"\n",
        "        ]\n",
        "\n",
        "    print(\"\\nTesting trained XLM-RoBERTa multilingual model...\")\n",
        "\n",
        "    try:\n",
        "        # Load model and tokenizer\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        # Fix: Load tokenizer from original model name instead of saved directory\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Determine label names based on number of labels\n",
        "        num_labels = model.config.num_labels\n",
        "        if num_labels == 2:\n",
        "            label_names = [\"NSFW\", \"Safe\"]\n",
        "        elif num_labels == 3:\n",
        "            label_names = [\"NSFW\", \"Safe\", \"Safe\"]  # 0=NSFW, 1=Safe, 2=Safe\n",
        "        else:\n",
        "            label_names = [f\"Class_{i}\" for i in range(num_labels)]\n",
        "\n",
        "        language_names = [\"English\", \"Spanish\", \"Tagalog\", \"French\", \"German\", \"Italian\", \"Portuguese\"]\n",
        "\n",
        "        for i, text in enumerate(test_texts):\n",
        "            # Determine language\n",
        "            lang_idx = i // 3  # 3 samples per language\n",
        "            language = language_names[lang_idx] if lang_idx < len(language_names) else \"Unknown\"\n",
        "\n",
        "            # Tokenize\n",
        "            inputs = tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                max_length=256,\n",
        "                padding=True\n",
        "            )\n",
        "\n",
        "            # Predict\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "                predicted_class = torch.argmax(predictions, dim=-1).item()\n",
        "                confidence = predictions[0][predicted_class].item()\n",
        "\n",
        "            # Map predictions to labels for display\n",
        "            if num_labels == 3:\n",
        "                # Convert 3-class to binary for display\n",
        "                display_class = 0 if predicted_class == 0 else 1\n",
        "                display_label = \"NSFW\" if display_class == 0 else \"Safe\"\n",
        "                # Calculate combined Safe confidence for classes 1 and 2\n",
        "                if predicted_class == 0:\n",
        "                    display_confidence = confidence\n",
        "                else:\n",
        "                    display_confidence = (predictions[0][1] + predictions[0][2]).item()\n",
        "            else:\n",
        "                display_label = label_names[predicted_class] if predicted_class < len(label_names) else f\"Class_{predicted_class}\"\n",
        "                display_confidence = confidence\n",
        "\n",
        "            print(f\"[{language}] Text: '{text[:80]}{'...' if len(text) > 80 else ''}'\")\n",
        "            print(f\"  -> {display_label} (confidence: {display_confidence:.4f})\")\n",
        "\n",
        "            # Show probabilities\n",
        "            if num_labels == 3:\n",
        "                nsfw_prob = predictions[0][0].item()\n",
        "                safe_prob = (predictions[0][1] + predictions[0][2]).item()\n",
        "                print(f\"  Probabilities: NSFW={nsfw_prob:.3f}, Safe={safe_prob:.3f}\")\n",
        "            else:\n",
        "                probs_str = \", \".join([f\"{label_names[j] if j < len(label_names) else f'Class_{j}'}={predictions[0][j].item():.3f}\"\n",
        "                                     for j in range(num_labels)])\n",
        "                print(f\"  Probabilities: {probs_str}\")\n",
        "            print()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Inference test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "h4L0c-BpAMb-"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROGRAM EXECUTION"
      ],
      "metadata": {
        "id": "yMtlQnqTAN2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Run the main pipeline\n",
        "        main()\n",
        "\n",
        "        # Optional: Test inference\n",
        "        test_inference(\"models/xlm_roberta_classification\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nTraining interrupted by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during execution: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"\\nProgram execution completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "31c747da8d934f38adf6fd4177d82e6f",
            "e888fe0f59454fd8be1adcc970bf8c6f",
            "386669778383468dabff518daab31c9b",
            "586e26dad1d549909594b25abaf7b92b",
            "2c52d55a68e24742adf23231607c8da4",
            "7bd2745b066e4d6894d913d6e615a298",
            "28a7b4d751f6408da8ce504190950a09",
            "15f353c742f0403aae3b546014cbebf8",
            "6014f7ebbf84451089d2a2c198215ebc",
            "bdb6e895839f4df89ca2ee1969c2e147",
            "3ac494f6437746f486749ff29e362659",
            "feb686e58f5a4fb0a9b05695d919d101",
            "68b439b653da46abb9fdf35a7129ea99",
            "90794681664441df8a68cc312a90213f",
            "cf82b58f2a824eadba97b0d99289e2be",
            "f2ff61ac46c24213a6a6383b813f2781",
            "3cccc9ac7c41422191bf55478b2560c1",
            "1646530e020d4d7cb5e617e66ff44bc6",
            "e17d4beebfb741f7a72bbd28695a7bd5",
            "ee5645bb694c4a10916aef46a5c8341e",
            "3fc786a8117646d7992d3ff9b95e3387",
            "6de0e7134b21407eaea84d55aea34c55"
          ]
        },
        "id": "fpFqxZNeAP5A",
        "outputId": "66385f7b-f334-4b5d-f284-2597d159b6e8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting XLM-RoBERTa Multilingual Text Classification Pipeline\n",
            "===========================================================================\n",
            "Using model: FacebookAI/xlm-roberta-base\n",
            "Output directory: models/xlm_roberta_classification\n",
            "Loading multilingual dataset from dataset.csv...\n",
            "Error: Dataset file 'dataset.csv' not found!\n",
            "Creating a sample multilingual dataset for demonstration...\n",
            "Sample multilingual sentiment dataset created and saved as 'dataset.csv'\n",
            "Dataset includes English, Spanish, Tagalog, French, and German samples\n",
            "Labels: 0=Negative, 1=Neutral, 2=Positive\n",
            "Total samples: 75 across 5 languages\n",
            "Splitting dataset: 20.0% for validation...\n",
            "Training set: 60 samples\n",
            "Validation set: 15 samples\n",
            "Loading XLM-RoBERTa tokenizer and creating tokenized datasets...\n",
            "Tokenizer vocabulary size: 250002\n",
            "Model max length: 512\n",
            "Tokenizing training dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/60 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31c747da8d934f38adf6fd4177d82e6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing validation dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "feb686e58f5a4fb0a9b05695d919d101"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete!\n",
            "Sample tokenized text length: 15\n",
            "Initializing XLM-RoBERTa model for multilingual classification training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1114163256.py:91: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded with 278,045,955 parameters\n",
            "Model architecture: 768 hidden, 12 layers\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24/24 01:03, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to models/xlm_roberta_classification...\n",
            "Evaluating XLM-RoBERTa model performance...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics saved to metrics/xlm_roberta_metrics.txt\n",
            "Validation Accuracy: 0.8000\n",
            "F1-Score (Macro): 0.7619\n",
            "F1-Score (Weighted): 0.7937\n",
            "Exporting XLM-RoBERTa model to ONNX format...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1086474918.py:21: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model exported to: models/xlm_roberta_classification_model.onnx\n",
            "ONNX model size: 1060.97 MB\n",
            "Converting XLM-RoBERTa PyTorch model to TensorFlow...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFXLMRobertaForSequenceClassification.\n",
            "\n",
            "All the weights of TFXLMRobertaForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved intermediate TensorFlow model to models/xlm_roberta_classification/tf_saved_model\n",
            "TFLite model successfully exported to: models/xlm_roberta_classification_model.tflite\n",
            "TFLite model size: 530.62 MB\n",
            "\n",
            "===========================================================================\n",
            "XLM-RoBERTa Multilingual Classification Training Complete!\n",
            "✅ ONNX model: models/xlm_roberta_classification_model.onnx\n",
            "✅ TFLite model: models/xlm_roberta_classification_model.tflite\n",
            "\n",
            "Model checkpoints: models/xlm_roberta_classification\n",
            "Metrics: metrics/xlm_roberta_metrics.txt\n",
            "Final validation accuracy: 0.8000\n",
            "\n",
            "Testing trained XLM-RoBERTa multilingual model...\n",
            "[English] Text: 'I absolutely love this amazing product, it's fantastic!'\n",
            "  -> Safe (confidence: 0.6567)\n",
            "  Probabilities: NSFW=0.343, Safe=0.657\n",
            "\n",
            "[English] Text: 'The product is okay, nothing particularly special about it.'\n",
            "  -> Safe (confidence: 0.6635)\n",
            "  Probabilities: NSFW=0.337, Safe=0.663\n",
            "\n",
            "[English] Text: 'Terrible quality, I'm completely disappointed with this purchase.'\n",
            "  -> Safe (confidence: 0.6517)\n",
            "  Probabilities: NSFW=0.348, Safe=0.652\n",
            "\n",
            "[Spanish] Text: 'Este producto es absolutamente increÃ­ble, me encanta mucho.'\n",
            "  -> Safe (confidence: 0.6544)\n",
            "  Probabilities: NSFW=0.346, Safe=0.654\n",
            "\n",
            "[Spanish] Text: 'El producto estÃ¡ bien, nada especialmente notable o destacable.'\n",
            "  -> NSFW (confidence: 0.3389)\n",
            "  Probabilities: NSFW=0.339, Safe=0.661\n",
            "\n",
            "[Spanish] Text: 'Calidad horrible, estoy completamente decepcionado con la compra.'\n",
            "  -> Safe (confidence: 0.6518)\n",
            "  Probabilities: NSFW=0.348, Safe=0.652\n",
            "\n",
            "[Tagalog] Text: 'Napakaganda ng produktong ito, sobrang satisfied ako dito!'\n",
            "  -> Safe (confidence: 0.6530)\n",
            "  Probabilities: NSFW=0.347, Safe=0.653\n",
            "\n",
            "[Tagalog] Text: 'Okay lang naman ang produkto, walang special na features.'\n",
            "  -> Safe (confidence: 0.6641)\n",
            "  Probabilities: NSFW=0.336, Safe=0.664\n",
            "\n",
            "[Tagalog] Text: 'Sobrang pangit ng quality, disappointed ako sa purchase na ito.'\n",
            "  -> Safe (confidence: 0.6504)\n",
            "  Probabilities: NSFW=0.350, Safe=0.650\n",
            "\n",
            "[French] Text: 'J'adore absolument ce produit, il est vraiment fantastique!'\n",
            "  -> Safe (confidence: 0.6540)\n",
            "  Probabilities: NSFW=0.346, Safe=0.654\n",
            "\n",
            "[French] Text: 'Le produit est correct, rien de particuliÃ¨rement remarquable vraiment.'\n",
            "  -> Safe (confidence: 0.6576)\n",
            "  Probabilities: NSFW=0.342, Safe=0.658\n",
            "\n",
            "[French] Text: 'QualitÃ© horrible, je suis complÃ¨tement dÃ©Ã§u de cet achat rÃ©cent.'\n",
            "  -> Safe (confidence: 0.6536)\n",
            "  Probabilities: NSFW=0.346, Safe=0.654\n",
            "\n",
            "[German] Text: 'Ich liebe dieses Produkt absolut, es ist wirklich fantastisch!'\n",
            "  -> Safe (confidence: 0.6537)\n",
            "  Probabilities: NSFW=0.346, Safe=0.654\n",
            "\n",
            "[German] Text: 'Das Produkt ist okay, nichts besonders Bemerkenswertes daran wirklich.'\n",
            "  -> Safe (confidence: 0.6564)\n",
            "  Probabilities: NSFW=0.344, Safe=0.656\n",
            "\n",
            "[German] Text: 'Schreckliche QualitÃ¤t, ich bin vÃ¶llig enttÃ¤uscht von diesem Kauf.'\n",
            "  -> Safe (confidence: 0.6519)\n",
            "  Probabilities: NSFW=0.348, Safe=0.652\n",
            "\n",
            "[Italian] Text: 'Amo assolutamente questo prodotto, Ã¨ davvero fantastico e perfetto!'\n",
            "  -> Safe (confidence: 0.6568)\n",
            "  Probabilities: NSFW=0.343, Safe=0.657\n",
            "\n",
            "[Italian] Text: 'Il prodotto va bene, niente di particolarmente notevole o speciale.'\n",
            "  -> Safe (confidence: 0.6597)\n",
            "  Probabilities: NSFW=0.340, Safe=0.660\n",
            "\n",
            "[Italian] Text: 'QualitÃ  orribile, sono completamente deluso da questo acquisto recente.'\n",
            "  -> Safe (confidence: 0.6527)\n",
            "  Probabilities: NSFW=0.347, Safe=0.653\n",
            "\n",
            "[Portuguese] Text: 'Eu amo absolutamente este produto, Ã© realmente fantÃ¡stico e perfeito!'\n",
            "  -> Safe (confidence: 0.6543)\n",
            "  Probabilities: NSFW=0.346, Safe=0.654\n",
            "\n",
            "[Portuguese] Text: 'O produto estÃ¡ bem, nada particularmente notÃ¡vel ou especial mesmo.'\n",
            "  -> NSFW (confidence: 0.3473)\n",
            "  Probabilities: NSFW=0.347, Safe=0.653\n",
            "\n",
            "[Portuguese] Text: 'Qualidade horrÃ­vel, estou completamente decepcionado com esta compra.'\n",
            "  -> Safe (confidence: 0.6509)\n",
            "  Probabilities: NSFW=0.349, Safe=0.651\n",
            "\n",
            "\n",
            "Program execution completed.\n"
          ]
        }
      ]
    }
  ]
}